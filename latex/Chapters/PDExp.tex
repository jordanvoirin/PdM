
\chapter{Phase Diversity Experiment} 
\label{ch:PDExp}

Here, we will describe the experiment put in place in the optical laboratory at the HEIG-VD to reconstruct wavefronts with unknown static aberrations introduced using phase screens. At first, we study the  behaviour of the phase diversity algorithm put in place by \citet{mugnier_2006} at ONERA with respect to number of averaging images, in other words noise level, and number of Zernike coefficients retrieved. Then we test the algorithm using a known aberration introduced by a parallel plane plate in the beam comparing the result to Zemax simulation. And finally, we introduce the phase screen to have random aberrations in the pupil and try to compare the phase diversity results with the Shack Hartman wavefront sensor results.

\section{Experimental Setup}
\label{sec:ExpSetup}
\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth,angle=0]{Figures/setupSchema.JPG}
\decoRule
\caption[Experimental Setup Schema]{Experimental setup schema with the relevant distances, \citep{Bouxin_PDM}.}
\label{fig:setupSchema}
\end{center}
\end{figure}

The design of the experiment was already done by \citet{Bouxin_PDM}. The system is built according to her plans and specifications. Figure \ref{fig:setupSchema} shows the schema of the experimental setup.

The experiment is mounted on a pressurized legs optical table. The assembly contains six main components : a light source, an entrance pupil, an imaging system, a converging lens to focus the beam on the camera, a camera and a wavefront sensor.

\subsection{Light source}
\label{subsec:LigthSource}

\begin{minipage}{\linewidth}
\begin{wrapfigure}{r}{0.4\textwidth}
\centering
\includegraphics[width=0.4\textwidth]{Figures/WFdistantSource.PNG}
\decoRulewrapFig
\caption[Wavefront curvature]{Wavefront curvature for different point source's distances, \textit{z}. \textit{r} represents the characteristic size of the arc of interest.}
\label{fig:WFdistantSource}
\end{wrapfigure}

The final application of the phase diversity will be to characterize the optical aberrations induced by the imperfect optical path to a scientific detector of a telescope. For this reason, the light source has to simulate a distant star aberration-free wavefront. A distant star wavefront is considered planar since the object distance, z, is far greater than the telescope size, r, see Fig. \ref{fig:WFdistantSource}. The source of our experiment must then be characterized by a planar wavefront.

In order to obtain such a planar wavefront at the entrance pupil, the light source consist of a "pigtailed laser diode", a f=11mm converging lens, a pinhole and a f=200 mm converging lens, see Table \ref{tab:optComp}. The pigtailed laser diode emits a Gaussian beam centred at 637.5 nm slightly diverging. The converging lens concentrates the beam at the center of the 10$\mu$m pinhole to filter the noise. The second converging lens collimates the beam, obtaining a collimated beam with a planar wavefront, see Fig. \ref{fig:sourceRayTracing} and \ref{fig:pinholeEffect}.

\end{minipage}

\begin{figure}
\centering
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=\textwidth]{Figures/source.png}
        \caption{Source ray tracing.}
        \label{fig:sourceRayTracing}
    \end{subfigure}
    \quad
    \begin{subfigure}{0.3\textwidth}
        \includegraphics[width=\textwidth]{Figures/pinholeEffect.png}
        \caption{Beam view before and after the pinhole, \citep{SpatialFilters}.}
        \label{fig:pinholeEffect}
    \end{subfigure}
    \decoRule
    \caption{Source schema and pinhole effect on the beam.}
\end{figure}

\subsection{Entrance pupil}
\label{subsec:EntrancePupil}

The entrance pupil of our optical system is a circular aperture of 3.2 mm diameter placed after the collimating lens of the light source. It is milled in a metal plate and centred in his support, to avoid positioning with a XY table. The diameter is chosen in available material to fit in the different detector's surfaces.

\subsection{Pupil imaging system}
\label{subsec:pupilImSystem}

The phase diversity technique requires PSFs images as input, which means that the beam as to be focused onto the detector surface. To analyse the aberration in the pupil plane, one needs to focus an image of the beam passing through the entrance pupil. The simplest assembly to achieve this goal is the 4F system, which consist of two converging lenses of focal 100 mm. The two lenses are separated by 200 mm, see Fig. \ref{fig:setupSchema}. This places the image of the entrance pupil 100 mm after the second converging lens.

\subsection{Detectors}
\label{subsec:Detectors}

The image of the entrance pupil, obtained with the 4F system, is focused onto a CMOS Ximea camera by a f = 80 mm converging lens to acquire the PSFs for the phase diversity wavefront retrieval. The camera has a surface composed by 1280x1024 pixels of 5.3 $\mu$m, see Appendix \ref{app:ximeaCam}. It is mounted on sliding support in order to be able to acquire in/out-of-focus images. A beam splitter is placed in the converging beam to separate it in two. The second beam is collimated and a Shack-Hartman WFS is placed on the entrance pupil image plane, to check the results of the phase diversity wavefront retrieval. The Shack-Hartman WFS has a 39 X 31 lenslets grid and a CCD with a resolution of 1280x1024 pixels of 4.65 $\mu$m, see Appendix \ref{app:SHwfs}. 

\begin{table}
\caption{Optical Components}
\label{tab:optComp}
\centering
\begin{tabular}{|l|l|l|c|}
\hline
\textbf{\#}& \textbf{Components} & \textbf{Model} & \textbf{Reference} \\\hline
1 & Pigtailed laser diode & Thorlabs, LPS-635-FC & \ref{app:pigtailedLaserDiode} \\\hline
2 & Converging lens, f = 11 mm & Thorlabs, A220TM-A & \ref{app:CL11} \\\hline
3 & Pinhole, 10 $\mu$m & Thorlabs, P10S & \ref{app:pinhole10microns} \\\hline
4 & Converging lens, f = 200 mm & Thorlabs, AL100200 & \ref{app:CL200} \\\hline
5 & 3.2 mm Hole milled in metal sheet & ... & ... \\\hline
6 & Converging lens, f = 100 mm & Thorlabs, AC254-100-A & \ref{app:CL100} \\\hline
7 & Converging lens, f = 80 mm & & \\\hline
8 & Camera CMOS & Ximea, MQ013MG-E2 & \ref{app:ximeaCam} \\\hline
9 & Converging lens, f = 100 mm & & \\\hline
10 & Shack-Hartman WFS & Thorlabs, WFS150-5C & \ref{app:SHwfs} \\\hline
\end{tabular}
\end{table}

\section{Data Acquisition}
\label{sec:DataAcquis}

\subsection{Ximea Camera}
\label{subsec:acquisXimCam}

The ONERA algorithm takes at least one focused and one defocused PSFs, as described in section \ref{subsec:OneraAlgoImp}. The PSFs are acquired using a python script which uses an open-source library to control the ximea camera, \verb|pyXimea|\footnote{\url{https://github.com/pupil-labs/pyximea}}, available on GitHub. The acquisition is done following these steps : 

\begin{enumerate}

\item The first step in order to acquire PSFs is to determine the position of the camera's focus point using the python script \verb|AlignementScriptXimeaCamera.py|, see Appendix \ref{subapp:AlignementScriptXimeaCamera}. This script let's you acquire consecutively PSFs at different camera's positions and computes their FWHM. It finally returns the minimum FWHM and the camera's position, see Figure \ref{subfig:28092017AlignementXimeaPSFs} and \ref{subfig:28092017AlignementXimeaPos}.

\begin{figure}
\centering
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\textwidth]{../../../fig/alignement/28092017AlignementXimeaPSFs.png}
        \caption{PSFs taken during the alignment procedure, each image is taken at an other camera position.}
        \label{subfig:28092017AlignementXimeaPSFs}
    \end{subfigure}
    \\
    \begin{subfigure}{0.6\textwidth}
        \includegraphics[width=\textwidth]{../../../fig/alignement/28092017AlignementXimeaPos.png}
        \caption{FWHM of the PSFs as a function of the camera's position. The minimum is at $11.55$ mm}
        \label{subfig:28092017AlignementXimeaPos}
    \end{subfigure}
    \decoRule
    \caption{Example of the results of an alignment procedure}
\end{figure}

\item Once the focus point position of the camera is determined, the acquisition of the data is possible. The acquisition script is called \verb!AcquisAndSaveXimea.py!, see Appendix \ref{subapp:AcquisAndSaveXimea}.

\item The user needs to set the main parameters before acquiring. They are the number of images on which to average, the size of the final PSFs, the position of the focus point on the sliding system and the initial guess to fit the 2D Gaussian on the PSF to find its center. The initial guess can be made using the Ximea camera software, called \verb!xiCamTool!, with which one gets a live feedback of the camera.

\item Then the running program ask the user what he needs to do after having made a sound. The first thing the user needs to do is to place the camera at the focus point and turn on the LED in order to set the optimal exposure time in order to avoid saturation.

\item Finally the acquiring sequence begins, the program ask the user to shut down and turn on the source as the user acquire the different images to get the dark images and the PSF images. The user needs to manually displace the camera to get the defocused PSFs. The program computes the positions to get a $2\pi$ P2V defocus dephasing.

\end{enumerate}

Many functions, used in the two scripts described above, are coded in the script \verb!functionsXimea.py!, see Appendix \ref{subapp:functionsXimea}.

\subsection{Shack-Hartmann WFS}
\label{subsec:acquisSHwfs}

The Shack-Hartmann wavefront sensor is delivered with a software which does the numerical integration to compute
the wavefront. The GUI shows the spot field (focal points), the beam view (irradiance of the
CCD), the wavefront measured or reconstructed (where you can choose the Zernike coefficients
to consider for the integration) and the Zernike coefficients.

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth,angle=0]{Figures/SHWFS_GUI}
\decoRule
\caption{Shack-Hartmann Software GUI, with the  beam view on the top left, the spot field in the middle and the reconstructed wavefront on the top right.}
\label{fig:}
\end{center}
\end{figure}

The acquisition is done with the company software. The acquired data are the Zernike coefficients and the reconstructed wavefront computed following the principle described in section \ref{subsec:SHprinciple}. Their is a few parameters that the user can set : the exposure time (there is also an auto set), the number of averaging images (1 up to 300) and the focus points reference of the micro-lenses array. 

The data are saved manually in a \textit{.csv} file. I coded an IDL script to read and average the Shack-Hartmann data, in order to be able to analyse them and compare the result with the phase diversity, see Appendix \ref{subapp:readAndAverageSHdata} and \ref{subapp:readSHWFSdata}. 

\section{Results}
\label{sec:Results}

This section presents the results of the phase diversity experiment, with the introduction of different sources of aberration. We will first present the results of the ONERA algorithm test, then we will compare the phase diversity retrieval with a calibrated aberration and finally we will introduce random static aberration with the phase screen and compare the results to the Shack-Hartmann wavefront sensor results.

\subsection{ONERA Phase Diversity test}
\label{subsec:ONERAPDtest}

The motivation of this test is to better understand the behaviour of the ONERA phase diversity algorithm with respect to the different parameters that could influence its results, such as the noise present in the PSFs, the number of Zernike coefficients returned for the modal mode and the error on the position of the Ximea camera.

\begin{figure}
\begin{center}
\includegraphics[width=0.6\textwidth,angle=0]{../../../fig/PD/noise_study/NoiseCurveXimea}
\decoRule
\caption{Noise level as a function of the number of averaging images acquired with $\sim$ 300 $\mu$s exposition time. The noise level is computed as the mean of the standard deviation of every pixel divided by the maximum of the focused PSF.}
\label{fig:NoiseCurve}
\end{center}
\end{figure}

To study the noise, we acquire PSFs with 25 different numbers of averaging images going from 10 to 5000. The noise level is computed as the ratio between the mean pixel standard deviation and the PSF maximum. The Ximea detector has a noise curve visible in Figure \ref{fig:NoiseCurve}. The noise curve is computed with the noise level of the focused PSFs. It follows an exponential law with the number of averaging images. The noise level varies from $\sim 1\mathrm{e}-3$ to $\sim 8\mathrm{e}-5$, for 10 and 5000 images respectively. Having the noise curve of the detector, we can study empirically how it influences the phase diversity results. 

\begin{figure}
\centering
    \begin{subfigure}{\textwidth}
        \includegraphics[width=\textwidth]{../../../fig/PD/noise_study/ZernikeCoef_J_differentNbrAveraging.png}
        \caption{Zernike coefficients $a_j$ as a function of $j$ the Zernike index of the 25 modal and zonal phase retrievals, in blue and red respectively.}
        \label{subfig:ZernikeCoef_J_differentNbrAveragingjmax30}
    \end{subfigure}
    \\
    \begin{subfigure}{0.75\textwidth}
        \includegraphics[width=\textwidth]{../../../fig/PD/noise_study/Boxplot_Aj_j_jmax30.png}
        \caption{Boxplot of the 25 Zernike coefficients $a_j$ of the different phase retrievals computed with the different averaging numbers of images as a function of the Zernike index $j$.}
        \label{subfig:Boxplot_Aj_j_jmax30}
    \end{subfigure}
    \decoRule
    \caption{Results of the phase retrievals computed with the 25 different noise levels. The phase retrievals are done with a $j_{max} = 30$}
\end{figure}

Figures \ref{subfig:ZernikeCoef_J_differentNbrAveragingjmax30} and \ref{subfig:Boxplot_Aj_j_jmax30} presents the results of the 25 different retrievals. As one can see there is some spread due to the different noise levels present in the PSFs given to the algorithm. The biggest standard deviation on a Zernike coefficient is smaller than 6 nm. And there can be up to 20 nm of maximal difference between the $a_j$'s as one can see on Figure \ref{subfig:Boxplot_Aj_j_jmax30}. The spherical aberration, $a_{11}$, has the biggest standard deviation and range of values. This shows that the PSFs noise levels have an impact on the retrieval and that not all Zernike coefficient are affected in the same way. One reassuring point is the good correspondence between the modal and zonal retrievals.

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth,angle=0]{../../../fig/PD/noise_study/WavefrontsNoiseStudy}
\decoRule
\caption{Reconstructed wavefronts for two different number of averaging images, 10 and 3500, left and right column respectively. The two first line are modal retrieval with $j_{max}=30$ and $j_{max}=200$ and the last line is the zonal retrieval.}
\label{fig:WavefrontsNoiseStudy}
\end{center}
\end{figure}

Furthermore, looking at the reconstructed wavefronts in Figure \ref{fig:WavefrontsNoiseStudy}, one can see the effect of noise in the PSFs and how important is the choice of $j_{max}$ for the modal reconstruction. Indeed, for the wavefronts reconstructed using $j_{max}=30$, the retrieved structures are similar, however for $j_{max}=200$ there are more structures in the retrieval done on the PSFs with 10 averaging images than with 3500 images. This shows that the noise has a signal at high spatial frequencies. The zonal retrieval shows it clearly, the reconstruction is significantly different between 10 and 3500 averaging images. The averaging over a large number of acquisition smooth out the noise structures that perturbs the reconstruction. Looking at the 25 reconstructed wavefront with the zonal method, the noise threshold is at 3500 averaging images to kill the effect of the noise. Also as said above for the Zernike coefficients and still valid for the wavefront, the two retrieval method gives similar results, as one can compare the three retrievals with 3500 images on the left column of Figure \ref{fig:WavefrontsNoiseStudy}. There is structures present on the wavefront reconstructed on 200 Zernike coefficients, but the footprint of the beam is similar to the two other reconstructions.


\begin{figure}
\begin{center}
\includegraphics[width=\textwidth,angle=0]{../../../fig/PD/noise_study/ZernikeCoef_J_differentJmax_5000Imgs.png}
\decoRule
\caption{Zernike coefficients $a_j$ as a function of $j$ for the 227 retrievals done for 231 different $j_{max}$ from 4 to 231.}
\label{fig:ZernikeCoef_J_differentJmax_5000Imgs}
\end{center}
\end{figure}

In order to be sure that the number of Zernike coefficient retrieved only influenced the wavefront reconstruction and not the $a_j$'s values, we computed them varying $j_{max}$ from 4 to 231 and found that the spread is negligible, see Figure \ref{fig:ZernikeCoef_J_differentJmax_5000Imgs}. This confirmation is expected since the Zernike polynomials are orthonormal, thus not correlated.

\begin{figure}
\centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{../../../fig/PD/errorDeltaZStudy/Boxplot_Aj_j.png}
        \caption{Boxplots of the 125 $a_j$'s retrieved with the modal method (blue) and zonal method (red). The PSFs are acquired with 5000 averaging images.}
        \label{subfig:Boxplot_Aj_j}
    \end{subfigure}
    \quad
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{../../../fig/PD/errorDeltaZStudy/Boxplot_stdAj.png}
        \caption{Boxplots of the 125 standard deviations on the Zernike coefficient for the modal and zonal method.}
        \label{subfig:Boxplot_stdAj}
    \end{subfigure}
    \decoRule
    \caption{Results of the $\Delta z$ measurement error test. The plots represent the results of the 125 phase retrievals run with all the permutations of errors, $[-2\sigma,-1\sigma,0,1\sigma,2\sigma]$ with $\sigma = 5\mathrm{e}-3$ mm, on the three PSFs position $\Delta z$}.
\end{figure}

Finally, the last test is to control the impact of a measurement error $\sigma_{\Delta z}$, the error position of the Ximea camera, on the phase retrieval. To do so the latter is run with 125 different permutations of the errors $[-2\sigma,-1\sigma,0,1\sigma,2\sigma]$ on the 3 PSFs position. $\sigma$ is set to represent the best precision we have on the position of the camera. As explained in section \ref{subsec:Detectors}, the camera is mounted on a sliding element moved by a micro metric screw, so $\sigma = 5\mathrm{e}-3$ mm. Figures \ref{subfig:Boxplot_Aj_j} and \ref{subfig:Boxplot_stdAj} present the results. The position error has nearly no effect on the phase retrieval, the median standard deviations are $\sim0.05$ nm and $\sim0.07$ nm for the modal and zonal method respectively.

In conclusion, the ONERA algorithm tests shows that first the two different methods, to retrieve the phase using the JMAP estimator, modal and zonal give similar results. Then, we have seen that the noise levels present in the PSFs influence the retrieval, see Figures \ref{subfig:ZernikeCoef_J_differentNbrAveragingjmax30}, \ref{subfig:Boxplot_Aj_j_jmax30} and \ref{fig:WavefrontsNoiseStudy}. We can consider the noise as an added aberration that touches all the Zernike coefficients. The spherical aberration is the most sensitive one. Also looking at the wavefronts, we see that there is a number of averaging images threshold at 3500 images for the zonal retrieval. Above this threshold the noise seems to be smooth and the retrieval looses the high spatial frequency components. The same thing is true for the modal retrieval, but the smoothing is not as effective at 3500 images. For the rest of this work each PSFs will be acquired with 5000 averaging images. Also we showed that the number of Zernike coefficient $j_{max}$ does not alter the modal retrieval. And finally, the error on the position of the camera also have a negligible impact.

\newpage
\subsection{Parallel plane plate}
\label{subsec:ParPlanePlate}

Now that we know how the algorithm behaves with respect to noise, $j_{max}$, etc... We compare its results to a calibrated aberration. The calibration is computed by simulating the optical system using Zemax. We introduce astigmatism using a plexiglas  parallel plane plate with an angle with respect to the optical axis.
